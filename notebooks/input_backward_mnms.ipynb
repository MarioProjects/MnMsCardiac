{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import environ\n",
    "import numpy as np\n",
    "from random import choices\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtrans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess.common import load_nii\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "# ---- My utils ----\n",
    "from utils.data_augmentation import data_augmentation_selector\n",
    "from utils.dataload import *\n",
    "from utils.training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8, 5\n",
    "plt.rc('grid', linestyle=\"--\", color='gray')\n",
    "\n",
    "# https://learnui.design/tools/data-color-picker.html#palette\n",
    "colors = ['#33508f', '#ff5d68', '#ffa600','#af4f9b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug, train_aug_img, val_aug = data_augmentation_selector(\"none\", 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_partition = \"validation\"\n",
    "general_aug, img_aug = train_aug, train_aug_img\n",
    "normalization = \"standardize\"\n",
    "fold_system = \"patient\"\n",
    "label_type = \"vendor_label_full\"\n",
    "data_fold = 0\n",
    "add_depth=False\n",
    "in_channels = 3 if add_depth else 1\n",
    "data_fold_validation=None\n",
    "\n",
    "discriminator_val_dataset = MMsDataset(\n",
    "    mode=data_partition, transform=train_aug, img_transform=train_aug_img,\n",
    "    folding_system=fold_system, normalization=normalization, label_type=label_type,\n",
    "    train_fold=data_fold, val_fold=data_fold_validation, add_depth=add_depth\n",
    ")\n",
    "\n",
    "discriminator_loader = DataLoader(discriminator_val_dataset, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_partition = \"validation\"\n",
    "general_aug, img_aug = train_aug, train_aug_img\n",
    "normalization = \"standardize\"\n",
    "fold_system = \"vendor\"\n",
    "label_type = \"mask\"\n",
    "\n",
    "\n",
    "segmentation_val_dataset = MMsDataset(\n",
    "    mode=data_partition, transform=general_aug, img_transform=img_aug,\n",
    "    folding_system=fold_system, normalization=normalization, label_type=label_type,\n",
    "    train_fold=\"A\", val_fold=\"B\",\n",
    ")\n",
    "\n",
    "segmentation_loader = DataLoader(segmentation_val_dataset, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_same_patients = np.intersect1d(discriminator_val_dataset.df[\"External code\"], segmentation_val_dataset.df[\"External code\"])\n",
    "print(f\"Pacientes en com√∫n ({len(val_same_patients)}): {val_same_patients}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes, crop_size, model_name = 3, 224, \"resnet34_unet_scratch_classification\"\n",
    "\n",
    "discriminator = model_selector(model_name, num_classes=num_classes, in_channels=in_channels)\n",
    "model_total_params = sum(p.numel() for p in discriminator.parameters())\n",
    "print(\"Model total number of parameters: {}\".format(model_total_params))\n",
    "discriminator = torch.nn.DataParallel(discriminator, device_ids=range(torch.cuda.device_count()))\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "model_checkpoint = \"../checkpoints/full_discriminator_{}channel_fold{}.pt\".format(in_channels, data_fold)\n",
    "discriminator.load_state_dict(torch.load(model_checkpoint))\n",
    "print(\"Discriminator checkpoint loaded correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes, crop_size, model_name = 4, 224, \"resnet34_unet_scratch\"\n",
    "\n",
    "segmentator = model_selector(model_name, num_classes=num_classes, in_channels=in_channels)\n",
    "model_total_params = sum(p.numel() for p in segmentator.parameters())\n",
    "print(\"Model total number of parameters: {}\".format(model_total_params))\n",
    "segmentator = torch.nn.DataParallel(segmentator, device_ids=range(torch.cuda.device_count()))\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "segmentation_train_fold = 'A'\n",
    "segmentation_val_fold = 'B'\n",
    "model_checkpoint = \"../checkpoints/segmentator_{}vs{}_{}channel.pt\".format(segmentation_train_fold, segmentation_val_fold, in_channels)\n",
    "segmentator.load_state_dict(torch.load(model_checkpoint))\n",
    "print(\"Segmentator checkpoint loaded correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check discriminator accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, weights_criterion = \"ce\", \"default\"\n",
    "criterion, weights_criterion, multiclass_criterion = get_criterion(criterion, weights_criterion)\n",
    "task = \"classification\" # binary_classification or classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, val_loss = val_step_accuracy(\n",
    "    discriminator_loader, discriminator, criterion, weights_criterion, multiclass_criterion, task=task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Discriminator accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check segmentator metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"../utils/data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"testa\", exist_ok=True)\n",
    "iou, dice, val_loss, stats = val_step(\n",
    "    segmentation_loader, segmentator, criterion, weights_criterion, multiclass_criterion, 0.5,\n",
    "    generate_stats=True, save_path=\"testa\",\n",
    "    generate_overlays=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stats(df, train_df):\n",
    "    df = df.fillna(1)\n",
    "    df[\"Vendor\"] = \"Z\"\n",
    "    df[\"Centre\"] = 999\n",
    "    df[\"Type\"] = \"XX\"\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "\n",
    "        patient = row[\"patient\"]\n",
    "        c_phase = row[\"phase\"]\n",
    "\n",
    "        centre = train_df.loc[train_df[\"External code\"]==patient].iloc[0][\"Centre\"]\n",
    "        vendor = train_df.loc[train_df[\"External code\"]==patient].iloc[0][\"Vendor\"]\n",
    "        c_type = train_df.loc[(train_df[\"External code\"]==patient) & (train_df[\"Phase\"]==int(c_phase))].iloc[0][\"Type\"]\n",
    "\n",
    "        df.at[i,'Vendor'] = vendor\n",
    "        df.at[i,'Centre'] = centre\n",
    "        df.at[i,'Type'] = c_type\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = clean_stats(stats, train_csv)\n",
    "same_stats = stats[stats['patient'].isin(val_same_patients)]\n",
    "same_stats[\"Vendor\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_stats.groupby(\"Vendor\")[\"IOU_MEAN\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_stats.groupby(\"Vendor\")[\"IOU_MEAN\"].mean().plot.bar(color=colors)\n",
    "# -------------------------------------------------------------- #\n",
    "plt.ylabel(\"Mean IOU\")\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.yticks(np.arange(0, same_stats.groupby(\"Vendor\")[\"IOU_MEAN\"].mean().max()+0.05, .05))\n",
    "plt.title(\"Mean IOU by Vendor\")\n",
    "plt.grid()\n",
    "#plt.savefig(os.path.join(save_dir, 'iou_vendor.png'), bbox_inches='tight', dpi=160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image modification using entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CXE(predicted, target):\n",
    "    return -(target * torch.log(predicted)).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Image modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = val_step_experiments(segmentation_loader, segmentator, val_same_patients, train_csv,\n",
    "                         num_classes=4, generate_imgs=False, image_modificator_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.groupby(\"Vendor\")[\"IOU_MEAN\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.groupby(\"Vendor\")[\"IOU_MEAN\"].mean().plot.bar(color=colors)\n",
    "# -------------------------------------------------------------- #\n",
    "plt.ylabel(\"Mean IOU\")\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.yticks(np.arange(0, stats.groupby(\"Vendor\")[\"IOU_MEAN\"].mean().max()+0.05, .05))\n",
    "plt.title(\"Mean IOU by Vendor\")\n",
    "plt.grid()\n",
    "#plt.savefig(os.path.join(save_dir, 'iou_vendor.png'), bbox_inches='tight', dpi=160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CXE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageBackwardEntropy:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, discriminator_model, target, max_epochs=500, \n",
    "                 out_threshold=0.01, grad_gamma=0.9, add_l1=False, l1_lambda=10, verbose=False):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        self.discriminator_model = discriminator_model\n",
    "        self.target = target\n",
    "        self.max_epochs = max_epochs\n",
    "        self.out_threshold = out_threshold\n",
    "        self.grad_gamma = grad_gamma\n",
    "        self.verbose = verbose\n",
    "        self.add_l1 = add_l1\n",
    "        self.l1_lambda = l1_lambda\n",
    "        \n",
    "\n",
    "    def apply(self, image):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        x = copy.deepcopy(image).detach()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            initial_y = torch.nn.functional.softmax(self.discriminator_model(x.detach()), dim=1)\n",
    "\n",
    "\n",
    "        for k in range(self.max_epochs):\n",
    "\n",
    "            x.requires_grad_(True)\n",
    "\n",
    "            y = torch.nn.functional.softmax(self.discriminator_model(x), dim=1)\n",
    "\n",
    "            # https://discuss.pytorch.org/t/catrogircal-cross-entropy-with-soft-classes/50871\n",
    "            error = CXE(y.cuda(), target.cuda())\n",
    "            if self.add_l1:\n",
    "                error = error + (torch.nn.L1Loss()(image.detach(), x) * self.l1_lambda)\n",
    "            error.backward()\n",
    "\n",
    "            x = x.detach() - self.grad_gamma*x.grad\n",
    "\n",
    "            if (y.cuda()-target.cuda()).abs().max() <= self.out_threshold: \n",
    "                break\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"\")\n",
    "            if (k+1) < self.max_epochs:\n",
    "                print(f\"----- Early stopping at iteration {k} -----\")\n",
    "            print(\"Target: {}\".format(target))\n",
    "            print(\"Initial y: {}\".format(['%.4f' % elem for elem in initial_y.tolist()[0]]))\n",
    "            print(\"Final y: {}\".format(['%.4f' % elem for elem in y.tolist()[0]]))\n",
    "            print(\"\")\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.from_numpy(np.array([1.0, 0.0, 0.0]))\n",
    "out_threshold = 0.01\n",
    "grad_gamma=0.99\n",
    "max_epochs=50\n",
    "\n",
    "image_modificator_fn = ImageBackwardEntropy(\n",
    "    discriminator, target, max_epochs=max_epochs, \n",
    "    out_threshold=out_threshold, grad_gamma=grad_gamma, verbose=False,\n",
    "    add_l1=True, l1_lambda=10\n",
    ")\n",
    "\n",
    "entropy_descriptor = \"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = val_step_experiments(\n",
    "    segmentation_loader, segmentator, val_same_patients, train_csv,\n",
    "    num_classes=4, generate_imgs=True, image_modificator_fn=image_modificator_fn,\n",
    "    save_dir=\"entropy_images/{}vs{}/{}/outThreshold{}_gradGamma{}_maxEpochs{}\".format(segmentation_train_fold, segmentation_val_fold, entropy_descriptor, out_threshold, grad_gamma, max_epochs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.groupby(\"Vendor\")[\"IOU_MEAN\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.groupby(\"Vendor\")[\"IOU_MEAN\"].mean().plot.bar(color=colors)\n",
    "# -------------------------------------------------------------- #\n",
    "plt.ylabel(\"Mean IOU\")\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.yticks(np.arange(0, stats.groupby(\"Vendor\")[\"IOU_MEAN\"].mean().max()+0.05, .05))\n",
    "plt.title(\"Mean IOU by Vendor\")\n",
    "plt.grid()\n",
    "#plt.savefig(os.path.join(save_dir, 'iou_vendor.png'), bbox_inches='tight', dpi=160)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
